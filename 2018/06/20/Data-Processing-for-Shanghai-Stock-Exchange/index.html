<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>上证所交易数据处理 | NJUCS-CVICSE</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-121783408-3','auto');ga('send','pageview');
</script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">上证所交易数据处理</h1><a id="logo" href="/.">NJUCS-CVICSE</a><p class="description">联合实验室工作日志</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">上证所交易数据处理</h1><div class="post-meta">Jun 20, 2018</div><div class="post-content"><h3 id="项目逻辑和代码说明"><a href="#项目逻辑和代码说明" class="headerlink" title="项目逻辑和代码说明"></a>项目逻辑和代码说明</h3><h4 id="主要实现"><a href="#主要实现" class="headerlink" title="主要实现"></a>主要实现</h4><p>根据已有静态历史数据文件（主要是对sh_20140312.zip这类文件中的Tick.csv做的处理），模拟每条记录产生后发送到kafka队列，然后使用flink流处理系统做实时处理，将结果放入hive数据仓库的过程。</p>
<h5 id="代码说明"><a href="#代码说明" class="headerlink" title="代码说明"></a>代码说明</h5><h5 id="Demo-SJ2Kafka"><a href="#Demo-SJ2Kafka" class="headerlink" title="Demo.SJ2Kafka"></a>Demo.SJ2Kafka</h5><p>这个类读取data/Tick.csv文件，创建一个KafkaProducer类将其中的数据按照顺序放入到Kafka队列中，其中Kafka broker 设置的是host13:9092， topic 是sj.</p>
<h5 id="com-dataartisans-flink-demo-examples-SJKafka2Hive"><a href="#com-dataartisans-flink-demo-examples-SJKafka2Hive" class="headerlink" title="com.dataartisans.flink_demo.examples.SJKafka2Hive"></a>com.dataartisans.flink_demo.examples.SJKafka2Hive</h5><p>执行这个类会创建一个flink任务，该任务的source是Kafka，sink是hive,对应的类分别是<code>com.dataartisans.flink_demo.sources。SJFromKafkaSource</code>和<code>com.dataartisans.flink_demo.sinks.HiveSink</code>.</p>
<p>主要做的事情就是从之前放入数据的Kafka队列拉取数据，做一个简单的map之后放入hive数据仓库。</p>
<p><img src="/images/sse/architecture-sse.png" alt="架构"></p>
<h3 id="写入hive"><a href="#写入hive" class="headerlink" title="写入hive"></a>写入hive</h3><p>个人理解是，Hive是对hdfs上的结构化数据文件做了一层关系型数据库的封装。当在hive中创建一个表时，指定这个表的location为hdfs上的一个directory，那个这个directory下的所有数据文件就是这个表中的数据，这些数据应该是结构化的类似csv格式的数据，并且格式与创建表时的schema对应。</p>
<p>那么不断对该directory增加数据文件，写入数据，就相当于传统关系型数据库的insert操作。</p>
<p>当在hive中对表执行一些SQL操作时，hive会把SQL语句转换成MapReduce任务，读取该表格对应的directory下的所有数据文件，得到结果。</p>
<p>使用flink系统将结果存入hive的过程，主要做的就是append/insert，所以可以使用flink的outputformat将结果直接以文件的形式写入到hdfs对应的目录下即可。注意这里写入的目录与hive中相应表格的location对应。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> testflink3 ( wasteId <span class="keyword">string</span>,<span class="keyword">time</span> <span class="keyword">timestamp</span>,locationx <span class="keyword">string</span>, LOCATIONY <span class="keyword">STRING</span>, stationId <span class="keyword">STRING</span>,stationName <span class="keyword">STRING</span>, vlp <span class="keyword">STRING</span>)</span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">','</span></span><br><span class="line">LOCATION <span class="string">'/user/root/testflink1'</span>;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> format = <span class="keyword">new</span> <span class="type">TextOutputFormat</span>[<span class="type">String</span>](<span class="keyword">new</span> <span class="type">Path</span>(<span class="string">"/user/root/testflink1"</span>))</span><br><span class="line">format.writeRecord(record)</span><br></pre></td></tr></table></figure>
<p>上面分别是创建hive中表格的命令和flink中输出目录，两者保持一致。另外，写入数据记录时，格式也要和表格的schema一致，包括各个属性，分隔符等。</p>
<h4 id="Hive中内部表与外部表的区别："><a href="#Hive中内部表与外部表的区别：" class="headerlink" title="Hive中内部表与外部表的区别："></a>Hive中内部表与外部表的区别：</h4><p>Hive 创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，<br>不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，<br>而外部表只删除元数据，不删除数据。这样外部表相对来说更加安全些，数据组织也更加灵活，方便共享源数据。 </p>
<p>需要注意的是传统数据库对表数据验证是 schema on write（写时模式），而 Hive 在load时是不检查数据是否<br>符合schema的，hive 遵循的是 schema on read（读时模式），只有在读的时候hive才检查、解析具体的<br>数据字段、schema。 </p>
<p>读时模式的优势是load data 非常迅速，因为它不需要读取数据进行解析，仅仅进行文件的复制或者移动。<br>写时模式的优势是提升了查询性能，因为预先解析之后可以对列建立索引，并压缩，但这样也会花费要多的加载时间。</p>
<h4 id="hive-table-directory"><a href="#hive-table-directory" class="headerlink" title="hive table directory"></a>hive table directory</h4><p>hive创建table后指定它的location为hdfs上的某个directory，此时这个表中的所有记录就是该directory下的数据文件，但不包括子目录下的数据文件。而且也无法或者很难配置做到让 hive查询数据的时候读取子目录。</p>
<p>由于这个特点，在输出的时候不能使用子目录。Flink默认的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/dev/connectors/filesystem_sink.html" target="_blank" rel="noopener">hdfs connector</a>使用的是Bucketing File Sink，会按照时间划分bucket，每一个bucket是一个子文件夹，格式是<code>/base/path/{date-time}/part-{parallel-task}-{count}</code>这样输出的数据不能被hive读取到。所以要自定义输出文件的目录格式。</p>
<p>自定义的hivesink使用filecount和indexofParallel进行命名，filesize设置为200000条记录。其中在filesize写满文件关闭时才写入磁盘。</p>
<p>另外一个可以注意的地方是以’_’开头的输入文件都会被忽略，这是Hadoop的一个特性。</p>
<h4 id="hive导出数据"><a href="#hive导出数据" class="headerlink" title="hive导出数据"></a>hive导出数据</h4><p>在终端中执行命令可以直接将sql语句的结果导出为数据文件。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive -e <span class="string">"select * from sjtable where time &lt; '2014-03-12 10:08:33' "</span>&gt; /root/SJ.CSV</span><br></pre></td></tr></table></figure>
<p>上面这条语句会将该表sjtable中时间在2014-03-12 10:08:33之前的数据导出到csv文件中。</p>
<p>默认的分隔符是tab\t,可以改成’,’等符号。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive -e <span class="string">'select * from some_table'</span> | sed <span class="string">'s/[\t]/,/g'</span> &gt; /home/yourfile.csv</span><br></pre></td></tr></table></figure>
</div><div class="tags"><a href="/tags/项目纪要/">项目纪要</a></div><div class="post-nav"><a class="pre" href="/2018/06/21/Graph-based-Enterprise-Portrait/">基于图数据库的企业画像</a><a class="next" href="/2018/05/10/Real-Time-Tolling/">高速计费实时数据处理框架</a></div><div id="container"></div><link rel="stylesheet" href="/css/default.css?v=0.0.0"><script src="/js/gitment.browser.js?v=0.0.0"></script><script>var gitment = new Gitment({
  owner: 'caochun',
  repo: 'comments-cvicse',
  oauth: {
    client_id: '502baa5b22416eebf178',
    client_secret: 'dede4f9ce1c22f8333524381b1d23895da54e660',
  },
})
gitment.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="http://cvicse.njuics.cn"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/学习笔记/" style="font-size: 15px;">学习笔记</a> <a href="/tags/项目纪要/" style="font-size: 15px;">项目纪要</a> <a href="/tags/个人小结/" style="font-size: 15px;">个人小结</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/10/30/Product-classification2/">质监数据学习技术报告</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/21/Automated-UI-Testing/">使用Selenium进行Web UI自动化测试</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/11/Learning-Scrapy/">基于Scrapy爬虫开发</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/27/Product-classification/">网络中的节点分类</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/07/Graph-Mining/">基于机器学习的质监预测技术</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/26/Data-Explaination/">质监数据说明</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/24/week-summary-suchuan/">南京大学学习周报-苏川</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/24/week-summary-pcq/">图数据库Neo4j学习总结-彭长青</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/23/First-Using-GitAndGithub/">Git与GitHub入门教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/21/Graph-based-Enterprise-Portrait/">基于图数据库的企业画像</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">NJUCS-CVICSE.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>